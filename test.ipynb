{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torchvision.models import resnet50\n",
    "from torchvision.models.detection import faster_rcnn\n",
    "import torch.nn.functional as F\n",
    "import sys\n",
    "sys.path.append('core')\n",
    "\n",
    "import argparse\n",
    "import os\n",
    "import cv2\n",
    "import glob\n",
    "import numpy as np\n",
    "import torch\n",
    "from PIL import Image\n",
    "\n",
    "from raft import RAFT\n",
    "from utils import flow_viz\n",
    "from utils.utils import InputPadder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEVICE = 'cuda'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Env\\anaconda3\\Lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "d:\\Env\\anaconda3\\Lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "resnet = resnet50(pretrained = True).to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conv1\n",
      "bn1\n",
      "relu\n",
      "maxpool\n",
      "layer1\n",
      "layer2\n",
      "layer3\n",
      "layer4\n",
      "avgpool\n",
      "fc\n"
     ]
    }
   ],
   "source": [
    "for name, _ in resnet.named_children():\n",
    "    print(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeatureExtractor(nn.Module):\n",
    "    def __init__(self, model : nn.Module) -> None:\n",
    "        super(FeatureExtractor, self).__init__()\n",
    "        self.feature = nn.Sequential(*list(model.children())[:-2])\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.feature(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flow_field (img1, img2, model, iters = 20):\n",
    "    _, flow_up = model(img1, img2, iters = 20, test_mode = True)\n",
    "    # (1, 2, H, W)\n",
    "    return flow_up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_image(imfile):\n",
    "    img = np.array(Image.open(imfile)).astype(np.uint8)\n",
    "    img = torch.from_numpy(img).permute(2, 0, 1).float()\n",
    "    return img[None].to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_warp(f_k : torch.Tensor, flow : torch.Tensor):\n",
    "    n, c, h, w = f_k.shape\n",
    "    kernel_size = 2\n",
    "    f_i = torch.zeros_like(f_k)\n",
    "    flo = F.interpolate(flow, size=(h,w), mode='bilinear', align_corners=False)\n",
    "\n",
    "    for px in range(w):\n",
    "        for py in range(h):\n",
    "            dpx = flo[:, 0:1, py, px]\n",
    "            dpy = flo[:, 1:, py, px]\n",
    "            i, j = torch.floor(py + dpy), torch.floor(px + dpx)\n",
    "            di, dj = py + dpy - i, px + dpx - j\n",
    "            G = torch.concat([di * dj, di * (1 - dj), (1 - di) * dj, (1 - di) * (1 - dj)], dim=1).reshape(n, 1, kernel_size, kernel_size)\n",
    "            # n, c, kernel, kernel\n",
    "            G = G.repeat(1, c, 1, 1).to(DEVICE)\n",
    "            grid = torch.zeros(n, kernel_size, kernel_size, 2).to(DEVICE)\n",
    "            for gy in range(kernel_size):\n",
    "                for gx in range(kernel_size):\n",
    "                    grid[:, gy, gx, 0:1] = 2 * (j + gx) / (w - 1) - 1\n",
    "                    grid[:, gy, gx, 1:] = 2 * (i + gy) / (h - 1) - 1\n",
    "            # n, c, kernel, kernel\n",
    "            patch = F.grid_sample(f_k, grid,  mode='bilinear', padding_mode='zeros', align_corners=True)\n",
    "            f_i[:,:, py, px] = torch.sum(G * patch, dim=(2, 3))\n",
    "\n",
    "    return f_i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "f_k= torch.randn(64, 2048, 7, 7).to(DEVICE)\n",
    "flow = torch.randn(64, 2, 224, 224).to(DEVICE)\n",
    "f_i = feature_warp(f_k, flow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 2048, 7, 7])"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f_i.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torch.nn.DataParallel(RAFT(args))\n",
    "model.load_state_dict(torch.load(args.model))\n",
    "\n",
    "model = model.module\n",
    "model.to(DEVICE)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "w = torch.randn(10, 2048, 1, 1)\n",
    "f = torch.randn(10, 2048, 7, 7)\n",
    "a = f*w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 2048, 7, 7])"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
